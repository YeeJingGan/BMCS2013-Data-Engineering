{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b187be79-3006-4197-8b28-13a44e6c5edd",
   "metadata": {},
   "source": [
    "# 5.0 Event Streaming\n",
    "\n",
    "###### Author: Gan Yee Jing, Yeap Jie Shen\n",
    "###### Last Edited: 02/09/2024\n",
    "\n",
    "## 5.1 Kafka Streaming (Getting Raw News)\n",
    "### 5.1.1 Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a796e0b-53df-437c-a494-cc508f2b41a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(r'/home/student/RDS2S3G4_CLO2_B')\n",
    "\n",
    "from data_stores.hbaseClient import HBaseClient\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from fake_useragent import UserAgent\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b3435d-3d5e-4b18-9d78-f9536f75c07d",
   "metadata": {},
   "source": [
    "### 5.1.2 Instantiate Spark Session and HDFS Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c3efc67-e7b1-4d77-9ecf-08e2649d18b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/02 14:21:35 WARN Utils: Your hostname, Gan. resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/09/02 14:21:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/02 14:21:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/02 14:21:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/09/02 14:21:36 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Kafka Streaming').getOrCreate()\n",
    "hbase_client = HBaseClient(host = 'localhost', port = 9090)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fada386-01d6-4db8-b0cc-4b685c76c318",
   "metadata": {},
   "source": [
    "### 5.1.3 Defining Source URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80732875-b38b-406f-8b3c-018288a7c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'SELANGOR JOURNAL' URL\n",
    "url = 'https://selangorjournal.my/category/current/crime/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf089c3-ac30-4443-84a6-2932dfbe2dd3",
   "metadata": {},
   "source": [
    "### 5.1.4 Scraping News URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a33db902-665a-4237-96bf-ed990cdc4f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_urls = []\n",
    "\n",
    "# Create a Useragent instance\n",
    "user_agent = UserAgent()\n",
    "\n",
    "# Setup webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(f'user-agent={user_agent.random}')\n",
    "\n",
    "# Open Chrome on Ubuntu\n",
    "driver = webdriver.Chrome(options = options)\n",
    "\n",
    "# Get request\n",
    "driver.get(url)\n",
    "\n",
    "# Locate all news article urls element\n",
    "url_elements = driver.find_elements(By.CSS_SELECTOR, '.penci-link-post.penci-image-holder.penci-disable-lazy') \n",
    "\n",
    "# Retrrieve single news article url\n",
    "for url_element in url_elements:\n",
    "    url = url_element.get_attribute('href')\n",
    "    news_urls.append(url)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93262d0-51d5-44c9-a897-34bcd5310c21",
   "metadata": {},
   "source": [
    "### 5.1.5 Verifying Existence of Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390e3ced-10ea-413f-b61e-6e5316724b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving urls from HBase\n",
    "url_records = [\n",
    "        record[1][b'cf1:url'].decode('utf-8')\n",
    "        for record in hbase_client.read_keys('news', ['k' + str(i) for i in range(6690)], [\n",
    "            'cf1:url'\n",
    "        ])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45309b95-3c61-4073-ad1d-9386c25d049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both new urls and eixsting urls to set for easier checking\n",
    "new_urls_set = set(news_urls)\n",
    "old_urls_set = set(url_records)\n",
    "\n",
    "# Find common urls\n",
    "common_urls = old_urls_set.intersection(new_urls_set)\n",
    "\n",
    "# Discard common urls\n",
    "valid_news_urls = [url for url in new_urls_set if url not in common_urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad9c74-c56c-4419-bfb5-888f9c2d2e22",
   "metadata": {},
   "source": [
    "### 5.1.6 Scraping News "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ebe7a5-e99f-4214-bbf1-af03e9831d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# List to store all news data\n",
    "data = []\n",
    "\n",
    "# Retriving data from each news articles\n",
    "for url in valid_news_urls:\n",
    "    # Create a Useragent instance\n",
    "    user_agent = UserAgent()\n",
    "\n",
    "    # Setup webdriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(f'user-agent={user_agent.random}')\n",
    "\n",
    "    # Open Chrome on Ubuntu\n",
    "    driver = webdriver.Chrome(options = options)\n",
    "\n",
    "    try: \n",
    "        # Get Request\n",
    "        driver.get(url)\n",
    "    \n",
    "        # Retrieve headline\n",
    "        headline = driver.find_element(By.TAG_NAME, \"h1\").text\n",
    "\n",
    "        # Retrieve date of published\n",
    "        date = driver.find_element(By.TAG_NAME, \"time\").get_attribute('datetime')\n",
    "\n",
    "        # Retrieve news text\n",
    "        content_wrapper = driver.find_element(By.CLASS_NAME,\"dable-content-wrapper\")\n",
    "        texts = content_wrapper.find_elements(By.TAG_NAME, \"p\")\n",
    "        article_content = ''\n",
    "\n",
    "        for text in texts:\n",
    "        \tarticle_content += text.text + ' '\n",
    "\n",
    "        # Create a dictionary for single news article\n",
    "        news_item ={\n",
    "            'url' : url,\n",
    "            'headline' : headline,\n",
    "            'datetime' : date,\n",
    "            'content' : article_content,\n",
    "            'publisher' : 'Selangor Journal',\n",
    "            'author' : ''\n",
    "        }\n",
    "\n",
    "        # Append to final list\n",
    "        data.append(news_item)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Unknown error occured')\n",
    "        continue\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0debc1f1-701d-4afe-8bf1-bc6afc9d403e",
   "metadata": {},
   "source": [
    "### 5.1.7 Publishing Scarpped News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b80987e9-05e6-43f7-bd96-48ca49c9dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initailise producer\n",
    "# kafka-topics.sh --delete --bootstrap-server localhost:9092 --topic CrimeNews\n",
    "# kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic CrimeNews\n",
    "\n",
    "producer = KafkaProducer(value_serializer=lambda v: json.dumps(v).encode('utf-8'), bootstrap_servers='localhost:9092')\n",
    "\n",
    "topic = 'CrimeNews'\n",
    "\n",
    "# Publish \n",
    "for news in data:\n",
    "    producer.send(topic=topic, value=news)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb4d8982-361d-4222-a5bd-f4c0c9144d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-venv",
   "language": "python",
   "name": "de-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
